{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExZw1V1M39rk"
      },
      "source": [
        "#Fake News Classification Task:\n",
        "Using word2vec to encode sentences into index which refers to the nth frequency in corpus. Ths corpus is constructed based on training and test data. Then apply bidirectional LSTM to train on training data. The best model is saved with the highest validaiton accuracy. Make prediction on test data based on this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5SAq9WE39rm"
      },
      "source": [
        "# Step 1)  Import packages and set parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv4ZNoRx39rm"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYslq2E539rr"
      },
      "source": [
        "### Setting paramiters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL5uSaK-39rr"
      },
      "source": [
        "max_features = 40000 #This is highest frequency threshold for all indices.\n",
        "maxlen = 500  # cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "408icqMmBTec"
      },
      "source": [
        "import re  # For preprocessing\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency\n",
        "import spacy  # For preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GwZqWDI39ru"
      },
      "source": [
        "# Step 2) Unzip and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNpm_Zlv39sR"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"train.csv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxDpAWnW5ROk"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"test.csv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A64QQtRH5v6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e238860-f680-4121-9f55-7c70491c2658"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('./train.csv',header=0)\n",
        "print(df.columns)\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['id', 'title', 'text', 'date', 'is_fake'], dtype='object')\n",
            "(35395, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHSyHdwbs9sR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd5c978-562b-4417-f894-b9e4904474ce"
      },
      "source": [
        "#how many training data we have:\n",
        "num_of_train=df.shape[0]\n",
        "num_of_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6assRBDmfkQv"
      },
      "source": [
        "#load test data as df_test.\n",
        "df_test=pd.read_csv('./test.csv',header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BHRYVLHPYW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0a0fbd-7e41-49b3-ca6c-6962eda9adf0"
      },
      "source": [
        "#names of columns of training data:\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'title', 'text', 'date', 'is_fake'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rr6XwdFBWPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af33ce3-9541-4aa3-826e-b2537127df58"
      },
      "source": [
        "df.isnull().sum() #no missing data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id         0\n",
              "title      0\n",
              "text       0\n",
              "date       0\n",
              "is_fake    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txp2bIyY_1Ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927031e8-f66b-446a-8ff9-403cd970ac1f"
      },
      "source": [
        "#extract only text column from training and test data:\n",
        "text=df.text\n",
        "text_test=df_test.text\n",
        "print(text.shape)\n",
        "print(text_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35395,)\n",
            "(8849,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drP-FQnanwbn"
      },
      "source": [
        "combine training's text and test's text together to get bag of words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWWgZ688nvqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55b04736-a7fa-43e7-a9ba-bfa112f4deef"
      },
      "source": [
        "text_combine=pd.concat([text,text_test])\n",
        "len(text_combine)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuAw77f1uG0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e54c6f-49a3-404c-e2b0-0f10dc26ba24"
      },
      "source": [
        "text_combine"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       21st Century Wire says WikiLeaks has released ...\n",
              "1       British Prime Minister Theresa May said on Wed...\n",
              "2       Well, get busy people! With the cyber attacks ...\n",
              "3       U.S. President Donald Trump will announce a ne...\n",
              "4       U.S. President Donald Trump gave his  in princ...\n",
              "                              ...                        \n",
              "8844    Johnny Carson must be rolling over in his grav...\n",
              "8845    Special Counsel Robert Muellers office has int...\n",
              "8846    Uzbek police released dissident writer Nurullo...\n",
              "8847    Liberals would like you to believe they re mor...\n",
              "8848    LIBERAL COMPASSION: This story is a perfect ex...\n",
              "Name: text, Length: 44244, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MW7Ip-_ATSz"
      },
      "source": [
        "y_train_fake=df.is_fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0h87dncSrPU"
      },
      "source": [
        "Bigrams:\n",
        "We are using Gensim Phrases package to automatically detect common phrases (bigrams) from a list of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KteAGiPeSQPx"
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp3FqjxySu9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61606492-7c28-46d4-bff4-5de5ac2e96fb"
      },
      "source": [
        "#As Phrases() takes a list of list of words as input:\n",
        "#Creates the relevant phrases from the list of sentences:\n",
        "sent = [row.split() for row in text_combine]\n",
        "phrases = Phrases(sent, min_count=20, progress_per=10000)\n",
        "#The goal of Phraser() is to cut down memory consumption of Phrases(), by discarding model state not strictly needed for the bigram detection task:\n",
        "sentences = phrases[sent]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju76DZBDTwxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe40d8b-580c-4b37-f573-2f55b5344d6e"
      },
      "source": [
        "#sent is list of words that contained in whole corpus\n",
        "sent[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['21st',\n",
              " 'Century',\n",
              " 'Wire',\n",
              " 'says',\n",
              " 'WikiLeaks',\n",
              " 'has',\n",
              " 'released',\n",
              " 'its',\n",
              " 'largest',\n",
              " 'ever']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9YcEd7vUPT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d12f49e-0938-45f0-c2d1-744fc93bc360"
      },
      "source": [
        "#sent is list of sentences for the whole training data and test data which broke down into list of words\n",
        "\n",
        "sentences[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['21st_Century',\n",
              " 'Wire_says',\n",
              " 'WikiLeaks',\n",
              " 'has',\n",
              " 'released',\n",
              " 'its',\n",
              " 'largest',\n",
              " 'ever',\n",
              " 'publication',\n",
              " 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijJdAPR_TLr8"
      },
      "source": [
        "Most Frequent Words:\n",
        "Mainly a sanity check of the effectiveness of the lemmatization, removal of stopwords, and addition of bigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA-Jh7UMTMV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a166008-5697-47f4-b20e-074cb6d063c0"
      },
      "source": [
        "word_freq = defaultdict(int)\n",
        "for sent in sentences:\n",
        "    for i in sent:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh32avXAZ5ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc90635b-1d3d-4a52-b507-b54f8ac6d405"
      },
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'to', 'of', 'and', 'a', 'in', 'that', 's', 'is', 'for']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUzLpiaZaJmr"
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6t_YwrAafcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a243a9b6-045e-4c9f-d259-dd38c203ac22"
      },
      "source": [
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
        "cores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC92sFP4NMgk"
      },
      "source": [
        "Preprocessing using word2vec:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFrVPeYoadAT"
      },
      "source": [
        "Training the model\n",
        "Gensim Word2Vec Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2yAcX74alCJ"
      },
      "source": [
        "w2v_model = Word2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5,\n",
        "                     alpha=0.03,\n",
        "                     min_alpha=0.0007,\n",
        "                     negative=20,\n",
        "                     workers=cores-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7elOQfravlh"
      },
      "source": [
        "Building the Vocabulary Table:\n",
        "Word2Vec requires us to build the vocabulary table (simply digesting all the words and filtering out the unique words, and doing some basic counts on them):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q69rl022awL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe87727-3a54-4285-fb4b-b85214aaa004"
      },
      "source": [
        "t = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 1.3 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw5MkdoRbfeZ"
      },
      "source": [
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tCcI_GBcEE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75523f4-6300-47f4-d65b-43693aab3bdb"
      },
      "source": [
        "#most similiar words to \"us\"\n",
        "w2v_model.wv.most_similar(positive=[\"us\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2017@IvankaTrump', 0.23851890861988068),\n",
              " ('casting_ballots', 0.22953510284423828),\n",
              " ('similar', 0.2292918562889099),\n",
              " ('seedy', 0.22645053267478943),\n",
              " ('Wednesday_evening', 0.22404953837394714),\n",
              " ('interest_rate', 0.22162044048309326),\n",
              " ('media_outlets', 0.21597148478031158),\n",
              " ('thru', 0.21518103778362274),\n",
              " ('renewed', 0.21356606483459473),\n",
              " ('delos', 0.2133629322052002)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nRb38O9kMCF"
      },
      "source": [
        "model_name = \"news_content_clean\"\n",
        "w2v_model.save(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m07veQ7kjhS"
      },
      "source": [
        "model = Word2Vec.load(\"news_content_clean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRbCtQGFfnC7"
      },
      "source": [
        "Train a full model, then access its model.wv property, which holds the standalone keyed vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2si4tdQcLDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7bd5eaf-c928-4388-968e-44e88b666cdd"
      },
      "source": [
        "word_vectors = model.wv.syn0 #array essentially holds raw word-vectors.these vectors are a 'projection layer' that can convert a one-hot encoding of a word into a dense embedding-vector of the right dimensionality.\n",
        "word_vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03872449,  0.02400741, -0.00940735, ..., -0.02864116,\n",
              "         0.08158486,  0.0011667 ],\n",
              "       [ 0.03810813, -0.03264292,  0.01746346, ...,  0.08693753,\n",
              "         0.08579368, -0.03509155],\n",
              "       [-0.00315781, -0.02290377, -0.09503513, ...,  0.0131291 ,\n",
              "         0.00495498,  0.0652029 ],\n",
              "       ...,\n",
              "       [ 0.02651773, -0.06607205,  0.09553516, ...,  0.0919237 ,\n",
              "        -0.07512816, -0.01320431],\n",
              "       [-0.01420887, -0.05685772, -0.01885691, ...,  0.04244019,\n",
              "         0.08878259, -0.07486628],\n",
              "       [ 0.01612616, -0.10234423, -0.09523982, ...,  0.05854018,\n",
              "        -0.01232063,  0.07443156]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKsTJnq5r2P4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07221d66-08fb-4690-b1a7-06d015656c38"
      },
      "source": [
        "#word2index is dictionary of all words as key and value is frequency in corpus:\n",
        "word2index = {token: token_index for token_index, token in enumerate(model.wv.index2word)}\n",
        "\"US\" in word2index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzWNO3wwuc6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4134d25-2ea7-412b-e450-9f83fcc79b29"
      },
      "source": [
        "len(word2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ora5G75lgva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbbfbe6-9c24-484d-963c-6b060e09037f"
      },
      "source": [
        "print(model.wv.index2word[:10])\n",
        "word=\"country\"\n",
        "print(model.wv.vocab.get(word).index)\n",
        "print(model.wv.vocab.get('language').index)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'to', 'of', 'and', 'a', 'in', 'that', 's', 'is', 'for']\n",
            "131\n",
            "1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jrbwm9tto84"
      },
      "source": [
        "Sentences_index are list of list of frequency corresponding to each word in our whole training data and test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPYuC-A2f2Mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e058f4-d763-49a9-ae93-dde176df549c"
      },
      "source": [
        "sentences_index=[]\n",
        "for news in sentences:\n",
        "    lst=[]\n",
        "    for word in news:\n",
        "      if word in word2index:#if the word is in corpus\n",
        "        if word2index[word]+1<max_features-1:#exclude extremely rare words\n",
        "           lst.append(word2index[word]+1)\n",
        "    sentences_index.append(lst)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljYuzm3suPSQ"
      },
      "source": [
        "dataset are cleaned, grouped as bigrams and encoded as word frequencies for  words as bag-of-words corpus: called this new dataset as \"sentences_index\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb-ok5A9t-e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221401c9-3bc1-4281-87d0-61b12795d43f"
      },
      "source": [
        "len(sentences_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KtNbrLMuz28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a8058f-70a6-4c7e-9495-70962c3bb7db"
      },
      "source": [
        "sentences_index[1][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4760, 5353, 404, 16, 285, 48, 3573, 928, 41, 25]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy4diSEut6GM"
      },
      "source": [
        "Split into training data and test data from sentences_index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im1vihW43hcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6c5b55-4541-4889-b043-02b7ce4ae70a"
      },
      "source": [
        "x_train_fake=sentences_index[:num_of_train]\n",
        "x_test_fake=sentences_index[num_of_train:]\n",
        "print(len(y_train_fake))\n",
        "print(len(x_train_fake))\n",
        "print(len(x_test_fake))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35395\n",
            "35395\n",
            "8849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07rXhS1n0eF2"
      },
      "source": [
        "# Reserve 7,000 samples for validation\n",
        "x_val = x_train_fake[-7000:]\n",
        "y_val = y_train_fake[-7000:]\n",
        "x_train = x_train_fake[:-7000]\n",
        "y_train = y_train_fake[:-7000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNLnXagYV70j"
      },
      "source": [
        "# create a callback that will save the best model while training\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lty8yBGo0vX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546d814e-40d5-4b72-e47c-404f095e7137"
      },
      "source": [
        "len(x_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW1rzDzZwhfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a843b1c4-b3c4-4626-d7e2-e2af59fbfc13"
      },
      "source": [
        "len(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLBpfn6Rsoi6"
      },
      "source": [
        "#Model training:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3jBvzme39ry"
      },
      "source": [
        "### Pad sequences\n",
        "Pad the word sequences in each sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1-IZsp_uEZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c56c9b4-0fab-4796-b766-aadeef67d83f"
      },
      "source": [
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (28395, 500)\n",
            "x_test shape: (7000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Q8Xbgu08AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820e25d2-e479-493d-ac69-a4417137dd73"
      },
      "source": [
        "print('Pad sequences (samples x time)')\n",
        "x_test_fake = sequence.pad_sequences(x_test_fake, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5L3XtxI1FnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e3b414-a782-4564-b9c5-cf160088834d"
      },
      "source": [
        "print('x_test shape:', x_test_fake.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test shape: (8849, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC4b8lXk39r1"
      },
      "source": [
        "# Step 3) Model Definition\n",
        "<b>Embedding layer:</b> Turns positive integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]<sup><a href=\"#R4\" target=\"_blank\">[4]</a></sup> This layer can only be used as the first layer in a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVjkSpzcw0qX"
      },
      "source": [
        "#Bidirectional LSTM:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHCI4gC-jcIV"
      },
      "source": [
        "from keras.layers import Bidirectional\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGIjO2c3zTyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1882ac73-2e0e-4636-d526-f47c6a695352"
      },
      "source": [
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 10, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(10, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(10)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iUFN_YPzqyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd158463-2e57-4d44-c343-7d50aee75a78"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 500, 10)           400000    \n",
            "_________________________________________________________________\n",
            "bidirectional_24 (Bidirectio (None, 500, 20)           1680      \n",
            "_________________________________________________________________\n",
            "bidirectional_25 (Bidirectio (None, 20)                2480      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 404,181\n",
            "Trainable params: 404,181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhTFoDPF39r8"
      },
      "source": [
        "# Step 4) Compiling model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVfI-aJnztDH"
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7yAxjcd39sA"
      },
      "source": [
        "# Step 5) Learning model and fit it on training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMRT4yENzyot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a21fe2-aeb7-4aa2-f70d-fc6fea0a3c8b"
      },
      "source": [
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,callbacks=[checkpoint],\n",
        "validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9366\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.98543, saving model to best_model.h5\n",
            "888/888 [==============================] - 72s 81ms/step - loss: 0.1687 - accuracy: 0.9366 - val_loss: 0.0495 - val_accuracy: 0.9854\n",
            "Epoch 2/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9895\n",
            "Epoch 00002: val_accuracy improved from 0.98543 to 0.99271, saving model to best_model.h5\n",
            "888/888 [==============================] - 70s 79ms/step - loss: 0.0388 - accuracy: 0.9895 - val_loss: 0.0306 - val_accuracy: 0.9927\n",
            "Epoch 3/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9951\n",
            "Epoch 00003: val_accuracy did not improve from 0.99271\n",
            "888/888 [==============================] - 71s 80ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.0271 - val_accuracy: 0.9920\n",
            "Epoch 4/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9970\n",
            "Epoch 00004: val_accuracy improved from 0.99271 to 0.99400, saving model to best_model.h5\n",
            "888/888 [==============================] - 71s 80ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
            "Epoch 5/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9977\n",
            "Epoch 00005: val_accuracy did not improve from 0.99400\n",
            "888/888 [==============================] - 71s 80ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0351 - val_accuracy: 0.9917\n",
            "Epoch 6/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9984\n",
            "Epoch 00006: val_accuracy did not improve from 0.99400\n",
            "888/888 [==============================] - 72s 81ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0249 - val_accuracy: 0.9939\n",
            "Epoch 7/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9988\n",
            "Epoch 00007: val_accuracy improved from 0.99400 to 0.99543, saving model to best_model.h5\n",
            "888/888 [==============================] - 72s 81ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0200 - val_accuracy: 0.9954\n",
            "Epoch 8/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9989\n",
            "Epoch 00008: val_accuracy improved from 0.99543 to 0.99614, saving model to best_model.h5\n",
            "888/888 [==============================] - 71s 80ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0193 - val_accuracy: 0.9961\n",
            "Epoch 9/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9994\n",
            "Epoch 00009: val_accuracy did not improve from 0.99614\n",
            "888/888 [==============================] - 72s 81ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0571 - val_accuracy: 0.9904\n",
            "Epoch 10/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9991\n",
            "Epoch 00010: val_accuracy did not improve from 0.99614\n",
            "888/888 [==============================] - 72s 81ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0375 - val_accuracy: 0.9911\n",
            "Epoch 11/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 00011: val_accuracy did not improve from 0.99614\n",
            "888/888 [==============================] - 72s 81ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0550 - val_accuracy: 0.9927\n",
            "Epoch 12/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 00012: val_accuracy did not improve from 0.99614\n",
            "888/888 [==============================] - 71s 80ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0563 - val_accuracy: 0.9916\n",
            "Epoch 13/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995\n",
            "Epoch 00013: val_accuracy improved from 0.99614 to 0.99629, saving model to best_model.h5\n",
            "888/888 [==============================] - 71s 80ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0296 - val_accuracy: 0.9963\n",
            "Epoch 14/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9996\n",
            "Epoch 00014: val_accuracy did not improve from 0.99629\n",
            "888/888 [==============================] - 67s 75ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0597 - val_accuracy: 0.9940\n",
            "Epoch 15/15\n",
            "888/888 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9997\n",
            "Epoch 00015: val_accuracy did not improve from 0.99629\n",
            "888/888 [==============================] - 71s 80ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0469 - val_accuracy: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2d3ceffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULzsCKKW15gC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790175a4-78ea-4f39-fc1c-1e3880803e47"
      },
      "source": [
        "print('Evaluating model...')\n",
        "score, acc = model.evaluate(x_val, y_val,\n",
        "                            batch_size=batch_size)\n",
        "print('\\n\\nTest score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model...\n",
            "219/219 [==============================] - 7s 32ms/step - loss: 0.0469 - accuracy: 0.9941\n",
            "\n",
            "\n",
            "Test score: 0.046872563660144806\n",
            "Test accuracy: 0.9941428303718567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUJPs24YXSoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b17bf3c-0343-4973-b311-a6d2f74b4d38"
      },
      "source": [
        "# Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
        "saved_model = keras.models.load_model('best_model.h5')\n",
        "scores = saved_model.evaluate(x_val, y_val, verbose=1)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "219/219 [==============================] - 7s 32ms/step - loss: 0.0296 - accuracy: 0.9963\n",
            "Test accuracy: 0.9962857365608215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INjFSHCMyIgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a354c6c-fdab-46c3-d003-722156921561"
      },
      "source": [
        "np.array(x_test_fake)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ..., 25400,  3737,  2334],\n",
              "       [    0,     0,     0, ..., 33714,  7295, 17087],\n",
              "       [    0,     0,     0, ...,     1,  3243, 18504],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,   130, 33453,  1168],\n",
              "       [    0,     0,     0, ...,     3, 25181,   323],\n",
              "       [    0,     0,     0, ...,     6,    33,    51]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmdG7meVyVwe"
      },
      "source": [
        "import torch\n",
        "x_test_fake_tensor = torch.FloatTensor(x_test_fake)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUjWHg_p39sJ"
      },
      "source": [
        "## Evaluate and predict labels of test data based on model corresponding to best validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4eOakLeFHd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d6366f-99b3-4c1c-9157-f473b50d90cb"
      },
      "source": [
        "y_prd = model.predict(np.array(x_test_fake_tensor))\n",
        "print(y_prd)\n",
        "y_prd = [1 if v > 0.5 else 0 for v in y_prd]\n",
        "print('First ten predicted label and true label of test data')\n",
        "print(np.array(y_prd[0:10]))\n",
        "len(y_prd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0000000e+00]\n",
            " [9.9999988e-01]\n",
            " [1.0000000e+00]\n",
            " ...\n",
            " [4.7378212e-09]\n",
            " [9.9999988e-01]\n",
            " [9.9999988e-01]]\n",
            "First ten predicted label and true label of test data\n",
            "[1 1 1 1 0 1 1 0 1 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e44AgT8uq8Xs"
      },
      "source": [
        "#Predict on test data and write out to csv file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfxQ9HG7OyIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf400ea-7f1a-4bd8-b930-7e0cf0e25157"
      },
      "source": [
        "df_test.id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       35395\n",
              "1       35396\n",
              "2       35397\n",
              "3       35398\n",
              "4       35399\n",
              "        ...  \n",
              "8844    44239\n",
              "8845    44240\n",
              "8846    44241\n",
              "8847    44242\n",
              "8848    44243\n",
              "Name: id, Length: 8849, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uc8YguXRjcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f60f75-cf46-4e00-fbd7-12d9eacae152"
      },
      "source": [
        "predict=np.stack((df_test.id,np.array(y_prd).T),axis=1)\n",
        "predict.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8849, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tMVHhB4mn76"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('Annetta Qi.csv', mode='w') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow(['id','is_fake'])\n",
        "    writer.writerows(predict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}